<!-- Generated by SpecStory -->

# Hugging Face API Quota Inquiry (2025-04-03 15:49:58)

_**User**_

```
huggingface_hub.errors.HfHubHTTPError: 402 Client Error: Payment Required for url: https://router.huggingface.co/hf-inference/models/stabilityai/stable-diffusion-2-inpainting (Request ID: Root=1-67ee3d50-44017165644014b531529bab;db652428-0066-47f8-8f27-9845b7e6bfbe) You have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.
```

How can I fetch my API quota of HuggingFace (show it in @11_Quota.py )

---

_**Assistant**_



---

Let me create a page to display your HuggingFace API quota information. First, I'll check what's in the existing Quota page and explore the codebase to understand how you're authenticating with HuggingFace.

---

Read file: pages/11_Quota.py

---

Let me check how you're handling authentication with HuggingFace in other parts of the codebase:

---

<details>
            <summary>Grep search for "from huggingface_hub" • **11** files</summary>
        
| File | Line | Match |
|------|------|-------|
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/pages/10_HuggingFace_models.py` | L1 | `from huggingface_hub import HfApi` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/pages/10_HuggingFace_models.py` | L334 | `from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/pages/2_text_%2B_image_-%3E_image.py` | L3 | `from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/pages/3_text_-%3E_image.py` | L3 | `from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.specstory/history/2025-04-03_07-09-refining-hugging-face-model-retrieval-script.md` | L45 | `from huggingface_hub import HfApi` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.specstory/history/2025-04-03_07-09-refining-hugging-face-model-retrieval-script.md` | L219 | `from huggingface_hub import HfApi` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.specstory/history/2025-04-03_07-09-refining-hugging-face-model-retrieval-script.md` | L506 | `+ from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.specstory/history/2025-04-03_07-09-refining-hugging-face-model-retrieval-script.md` | L714 | `from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.specstory/history/2025-04-03_06-29-image-processing-script-with-ui-integration.md` | L44 | `+ from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.specstory/history/2025-04-03_01-17-model-filtering-and-data-display-features.md` | L3456 | `+ from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.specstory/history/2025-04-03_01-17-model-filtering-and-data-display-features.md` | L3470 | `- from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/pages/2_text_%2B_image_-%3E_image.py` | L3 | `from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/pages/3_text_-%3E_image.py` | L3 | `from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/__init__.py` | L19 | `#       used. This way, `from huggingface_hub import something` will import `something`` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L42 | `from huggingface_hub import constants` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L43 | `from huggingface_hub.errors import BadRequestError, InferenceTimeoutError` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L44 | `from huggingface_hub.inference._common import (` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L62 | `from huggingface_hub.inference._generated.types import (` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L102 | `from huggingface_hub.inference._providers import PROVIDER_T, HFInferenceTask, get_provider_helper` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L103 | `from huggingface_hub.utils import build_hf_headers, get_session, hf_raise_for_status` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L104 | `from huggingface_hub.utils._auth import get_token` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L105 | `from huggingface_hub.utils._deprecation import _deprecate_method` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L401 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L451 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L503 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L709 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L742 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L756 | `from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L780 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L794 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L807 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L924 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L1057 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L1130 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L1191 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L1243 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L1304 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L1380 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L1429 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L1482 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L1555 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L1610 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L1670 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L1734 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L1777 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L1831 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L1891 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L2179 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L2470 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L2485 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L2499 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L2513 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L2596 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L2611 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L2741 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L2750 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L2764 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L2777 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L2792 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L2889 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L2975 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L3047 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L3113 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L3141 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L3214 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L3287 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L3354 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L3411 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py` | L3463 | `>>> from huggingface_hub import InferenceClient` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/pages/10_HuggingFace_models.py` | L1 | `from huggingface_hub import HfApi` |
| `file:///Users/daviddwlee84/Documents/Program/Personal/Free-LLM-API/pages/10_HuggingFace_models.py` | L334 | `from huggingface_hub import InferenceClient` |

</details>

---

Let me check one of the HuggingFace files to understand how you're authenticating with the API:

---

Read file: pages/10_HuggingFace_models.py

---

Let me check the rest of the file to see if there's any authentication or token info:

---

Read file: pages/10_HuggingFace_models.py

---

Now I know how the codebase works with HuggingFace. Let's create a page to display the HuggingFace API quota information. The HuggingFace Hub API doesn't provide a direct method to check quota, but we can create a page that:

1. Shows information about the monthly credits based on account type
2. Provides a way to test the API and catch quota errors
3. Offers links to the billing page where the user can check their usage

Let me create the Quota page:

---

```diff
- 
+ import streamlit as st
+ import requests
+ from huggingface_hub import HfApi, InferenceClient
+ from huggingface_hub.utils import get_token
+ import json
+ 
+ # Page configuration
+ st.set_page_config(page_title="HuggingFace Quota", layout="wide")
+ st.title("HuggingFace API Quota Information")
+ 
+ # Information section
+ st.info("""
+ ## Monthly Included Credits
+ Hugging Face provides monthly credits for inference requests based on your account type:
+ - **Free Users**: Less than $0.10 (subject to change)
+ - **PRO Users**: $2.00
+ - **Enterprise Hub Organizations**: $2.00 per seat, shared among members
+ 
+ Once your credits are exhausted, you'll see a '402 Payment Required' error for inference requests.
+ """)
+ 
+ # Links to official quota/billing information
+ col1, col2 = st.columns(2)
+ with col1:
+     st.link_button("View Billing Settings", "https://huggingface.co/settings/billing")
+ with col2:
+     st.link_button("Pricing Documentation", "https://huggingface.co/docs/inference-providers/pricing")
+ 
+ # Check authentication status
+ token = get_token()
+ st.subheader("Authentication Status")
+ 
+ if token:
+     st.success("✅ HuggingFace token found")
+     
+     # Try to get user info to determine account type
+     try:
+         api = HfApi(token=token)
+         user_info = requests.get(
+             "https://huggingface.co/api/whoami",
+             headers={"Authorization": f"Bearer {token}"}
+         ).json()
+         
+         # Display basic user info
+         st.subheader("Account Information")
+         st.write(f"**Username**: {user_info.get('name', 'Unknown')}")
+         
+         account_type = "Free"
+         if user_info.get('isPro'):
+             account_type = "PRO"
+         
+         st.write(f"**Account Type**: {account_type}")
+         
+         # Show estimated quota based on account type
+         st.subheader("Estimated Monthly Credits")
+         if account_type == "PRO":
+             st.write("Monthly Credits: $2.00")
+         else:
+             st.write("Monthly Credits: Less than $0.10")
+             
+         st.info("For precise usage information, please check your [billing settings](https://huggingface.co/settings/billing).")
+     except Exception as e:
+         st.warning(f"Could not retrieve account information: {str(e)}")
+ else:
+     st.error("⚠️ No HuggingFace token found")
+     st.info("""
+     To use the HuggingFace API, you need to set up your token:
+     1. Create a token at [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)
+     2. Set the token as an environment variable: `export HUGGINGFACE_TOKEN=your_token`
+     3. Or use `huggingface-cli login` in your terminal
+     """)
+ 
+ # Test quota section
+ st.subheader("Test Current Quota Status")
+ st.write("Run a simple inference test to check if you have available quota:")
+ 
+ test_model = st.selectbox(
+     "Select model to test:",
+     [
+         "sentence-transformers/all-MiniLM-L6-v2",  # Small text embedding model (low cost)
+         "google/flan-t5-small",  # Small text generation model
+         "stabilityai/stable-diffusion-2-1-base"  # Image generation (higher cost)
+     ]
+ )
+ 
+ if st.button("Test Quota"):
+     with st.spinner("Testing API quota..."):
+         try:
+             client = InferenceClient()
+             
+             if "sentence-transformers" in test_model:
+                 # Testing embedding model
+                 result = client.feature_extraction(
+                     "Hello world",
+                     model=test_model
+                 )
+                 st.success("✅ API call successful! You have available quota.")
+                 
+             elif "flan-t5" in test_model:
+                 # Testing text generation
+                 result = client.text_generation(
+                     "Translate to French: Hello, how are you?",
+                     model=test_model
+                 )
+                 st.success(f"✅ API call successful! You have available quota.\n\nResponse: {result}")
+                 
+             elif "stable-diffusion" in test_model:
+                 # Testing image generation (most expensive)
+                 result = client.text_to_image(
+                     "a photo of a cat",
+                     model=test_model
+                 )
+                 st.success("✅ API call successful! You have available quota.")
+                 st.image(result)
+                 
+         except Exception as e:
+             error_msg = str(e)
+             if "402" in error_msg and "Payment Required" in error_msg:
+                 st.error("❌ Quota exceeded! You have exhausted your monthly credits.")
+                 st.info("Consider upgrading to PRO for more credits or wait until your quota resets next month.")
+             else:
+                 st.error(f"❌ Error during API call: {error_msg}")
+ 
+ # Usage tips section
+ with st.expander("Tips for Managing Quota"):
+     st.markdown("""
+     ### Conserve Your Credits
+     - Use smaller models when possible
+     - Cache results for repeated queries
+     - Set appropriate timeout values
+     - Test with small inputs before scaling
+     
+     ### Billing Organization
+     If you're part of an organization with Enterprise Hub:
+     ```python
+     from huggingface_hub import InferenceClient
+     
+     # Bill to organization instead of personal account
+     client = InferenceClient(provider="provider-name", bill_to="your-org-name")
+     ```
+     """)
+ 
```

---

I've created a comprehensive HuggingFace quota information page at `pages/11_Quota.py`. The page:

1. Displays information about the monthly credits based on account type
2. Shows your authentication status and account information
3. Provides a test feature to check if you have available quota
4. Includes links to official HuggingFace billing pages
5. Offers tips for managing your quota

Unfortunately, HuggingFace doesn't provide a direct API to check your exact remaining quota or credit usage. The most accurate way to check your quota is to:

1. Look at your billing page on the HuggingFace website (linked in the app)
2. Test if an API call works or returns a 402 error (which the app lets you do)

You can run this page using Streamlit to see your quota status. If you encounter the 402 error again, you'll know you've exceeded your monthly credits and need to either upgrade to PRO or wait until your quota resets.

---



---

